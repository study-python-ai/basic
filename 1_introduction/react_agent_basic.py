from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.tools import TavilySearchResults
from langgraph.prebuilt import create_react_agent
from langchain_core.messages import HumanMessage
from langchain_core.tools import tool

# í™˜ê²½ì„¤ì •
load_dotenv()

# tools
search_tool = TavilySearchResults(search_depth="basic")


@tool
def get_system_time(format: str = "%Y-%m-%d %H:%M:%S") -> str:
    """ì˜¤ëŠ˜ ë‚ ì§œì™€ ì‹œê°„ì„ ì§€ì •ëœ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    from datetime import datetime

    return datetime.now().strftime(format)


# LLM
llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash")

# agent ìƒì„±
agent = create_react_agent(llm, [search_tool, get_system_time])

# ë°©ë²• 1: LangGraphì˜ ê°„ë‹¨í•œ ë””ë²„ê·¸ ëª¨ë“œ
print("=== ë°©ë²• 1: ê°„ë‹¨í•œ ì‹¤í–‰ (verbose ìŠ¤íƒ€ì¼) ===")
query = "ëŒ€í•œë¯¼êµ­ ëŒ€í†µë ¹ì´ ì„ ì¶œëœì§€ ëª‡ ì¼ì´ ì§€ë‚¬ë‚˜ìš”"
messages = [HumanMessage(content=query)]

# ê°„ë‹¨í•˜ê²Œ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë§Œ ë³´ê¸°
result = agent.invoke({"messages": messages})
print("Final result:", result["messages"][-1].content)

print("\n" + "=" * 50)
print("=== ë°©ë²• 2: ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ìƒì„¸ ê³¼ì • ë³´ê¸° ===")

# ìƒì„¸í•œ ê³¼ì •ì„ ë³´ê³  ì‹¶ë‹¤ë©´ ìŠ¤íŠ¸ë¦¬ë° ì‚¬ìš©
for step in agent.stream({"messages": messages}):
    for node, data in step.items():
        if "messages" in data:
            for msg in data["messages"]:
                if hasattr(msg, "tool_calls") and msg.tool_calls:
                    for tool_m in msg.tool_calls:
                        print(f"ğŸ”§ ë„êµ¬ ì‚¬ìš©: {tool_m['name']}")
                        print(f"   ì…ë ¥: {tool_m['args']}")
                elif hasattr(msg, "name") and msg.name:
                    print(f"âœ… ë„êµ¬ ê²°ê³¼: {msg.content[:200]}...")
                elif msg.content and not hasattr(msg, "tool_calls"):
                    print(f"ğŸ’­ ìµœì¢… ë‹µë³€: {msg.content}")

print("\n=== ì™„ë£Œ ===")
